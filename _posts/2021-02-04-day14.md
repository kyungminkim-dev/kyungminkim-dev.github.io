---
title:  "Day14 학습정리"
excerpt: "DL Basic"

categories:
  - Blog
tags:
  - [Blog, jekyll, Github, Git]
use_math: true
toc: true
toc_sticky: true
 
date: 2021-02-04
last_modified_at: 2021-02-15
---

# day14 학습정리
## [AI Math 10강] RNN 첫걸음

**시퀀스 데이터의 이해**

* 소리, 문자열, 주가 등의 데이터를 시퀀스(sequence) 데이터로 분류한다. 

* 시계열(time-series) 데이터는 시간 순서에 따라 나열된 데이터로 시퀀스 데이터에 속한다. 

* 시퀀스 데이터는 독립동등분포(i.i.d.) 가정을 잘 위배하기 때문에 순서를 바꾸거나 과거 정보에 손실이 발생하면 데이터의 확률분포도 바뀌게 된다. 

* 과거 정보 또는 앞뒤 맥락 없이 미래를 예측하거나 문장을 완성하는 것은 불가능 하다. 

<br><br/>

**시퀀스 데이터를 다루는 법**

* 이전 시퀀스의 정보를 가지고 앞으로 발생할 데이터의 확률분포를 다루기 위해 조건부확률을 이용할 수 있다.<br/>
    $P(X_1,...,X_t)=P(X_{t}|X_1,...,X_{t-1})P(X_1,...,X_{t-1})=P(X_{t}|X_1,...,X_{t-1})P(X_{t-1}|X_1,...,X_{t-2})P(X_1,...,X_{t-2}) = \prod_{s=1}^{t}P(X_{s}|X_{s-1},...,X_{1})$<br/>

    $X_{t} \sim P(X_t|X_{t-1},...,X_1)$
    
        
    * 위 조건부확률은 과거의 모든 정보를 사용하지만 시퀀스 데이터를 분석할 때 모든 과거 정보들이 필요한 것은 아니다.

* 시퀀스 데이터를 다루기 위해선 길이가 가변적인 데이터를 다룰 수 있는 모델이 필요하다.
    
    * 고정된 길이 $\tau$만큼의 시퀀스만 사용하는 경우 AR($\tau$) (Autoregressive Model) 자기회귀모델이라고 부른다. 

    * 또 다른 방법은 바로 이전 정보를 제외한 나머지 정보들을 $H_t$라는 잠재변수로 인코딩해서 활용하는 잠재 AR모델이다.

    * 잠재변수 $H_t$를 신경망을 통해 반복해서 사용하여 시퀀스 데이터의 패턴을  학습하는 모델이 RNN이다.
    
    * $X_{t} \sim P(X_t|X_{t-1},...,X_1)$
    

    * $X_{t+1} \sim P(X_{t+1}|X_{t},X_{t-1},...,X_1)$
    
    
    * $H_{t} = Net_{\theta}(H_{t-1},X_{t-1})$
    
<br><br/>

---

**Recurrent Neural Network의 이해**

* 가장 기본적인 RNN 모형은 MLP와 유사한 모양이다.

    * $W^{(1)}, W^{(2)}$은 시퀀스와 상관없이 불변이 행렬이다.<br/>

        $O_{t} = H_{t}W^{(2)} + b^{(2)}$<br/>

        $H_{t} = \sigma{(X_{t}W_{x}^{(1)} +H_{t-1}W_{H}^{(1)}+b^{(1)}})$  ($H$ : 잠재변수, $\sigma$ : 활성화함수, $W$ : 가중치행렬, $b$ : bias)

* RNN은 이전 순서의 잠재변수와 현재의 입력을 활용하여 모델링합니다.

* RNN의 역전파는 잠재변수의 연결그래프에 따라 순차적으로 계산한다. 이를 Backpropagation Through Time(BPTT)라 한다.




**기울기 소실의 해결책**

* 시퀀스 길이가 길어지는 경우 BPTT를 통한 역전파 알고리즘의 계산이 불안정해지므로 길이를 끊는 것이 필요하다. 이를 truncated BPTT라 한다.

* 이런 문제들 때문에 Vanilla RNN은 길이가 긴 시퀀스 처리하는데 문제가 있다. 이를 해결하기 위해 등장한 RNN네트워크가 LSTM 과 GRU이다. 


---


## [DLBasic] Sequential Models - RNN

**Sequential Model**

* Naive sequence model

    Input $x_{t-2} \longrightarrow x_{t-1} \longrightarrow x_{t}$<br/>

    $P(x_{t}|x_{t-1},x_{t-2},...)$

    $x_{t-1}, x_{t-2}...$ : The number of inputs varies.  
    
* Latent autogressive model

  $\hat{x} = p(x_t|h_t)$

  $h_t=g(h_{t-1},x_{t-1})$

  $h$ : summary of the past
  
* Short-term dependencies

  * 단기 시간정보에 영향을 많이 받고 먼 과거 정보의 영향력이 적어지는 문제점이 발생. 이를 해결하기 위해 나온 모델이 LSTM.

  ![image-Vanishing_RNN](../../assets/img/boostcamp/Vanishing_RNN.png)
    
  * activation function을 sigmoid를 사용한다면 layer를 지날수록 0~1값으로 squashing(정보를 줄임)시켜 값이 의미가 없어짐.<br/>
  
    ReLu를 사용했을 때, x가 양수라면 W의 값을 n번 곱하게됨. 따라서 $h_0$의 값이 $h_4$갈 때 엄청 크게 반영됨.
    
    
* Long Short Term Memory

  ![image-LSTM1](../../assets/img/boostcamp/LSTM1.png)
  
  ![image-LSTM2](../../assets/img/boostcamp/LSTM2.png)
  
  * Cell state : timestep t까지 들어오는 정보를 요약. 신경망 내부에서만 흘러감
  
    ![image-Cellstate](../../assets/img/boostcamp/Cellstate.png)
  
  * Forget gate : 현재의 입력($x_t$)와 이전의 output($H_{t-1}$)이 합쳐져 $f_{t}$(0~1사이의 값)를 만듦. $f_{t}$는 이전의 cell state에서 나오는 정보 중 어떤것을 버리고 어떤것을 살릴지 정함.  

    ![image-Forgetgate](../../assets/img/boostcamp/Forgetgate.png)

  * Input gate : 어떤정보를 cell state에 올릴지 말지를 결정함($i_{t}). 현재정보와 이전 출력값으로 학습 layer를 통과시켜 만든 $\tilde{C}$
  
    ![image-Inputgate](../../assets/img/boostcamp/Inputgate.png)
  
  * Update cell : 지금까지의 time sequence를 summarize하는 cell state를 update.
  
    ![image-Updatecell](../../assets/img/boostcamp/Updatecell.png)
  
  * Output gate : 이전까지의 정보를 현재의 정보를 바탕으로 어떤 값을 지울지, 현재정보를 바탕으로 어떤 값을 새롭게 쓸지를 취합한 Update cell중 어떤값을 밖으로 빼낼지를 정함.
  
    ![image-Outputgate](../../assets/img/boostcamp/Outputgate.png)
  
* Gated Recurrent Unit

  ![image-GRU](../../assets/img/boostcamp/GRU.png)

  * Simpler architechure with two gates (reset gate and update gate).
  
  * No cell state, just hidden state. hidden state가 곧 output이고 다음 단계로 들어감.(ouput gate가 사라짐)
  
  * 많은 경우 똑같은 모델에 대해서 GRU가 LSTM보다 성능이 좋다. 네트워크 파라미터가 GRU가 적다. 동일한 성능을 낼 때, 파라미터 수가 적으면 generalize perfromance가 올라간다.
