---
title:  "Day24 학습정리"
excerpt: "AI Math"

categories:
  - Blog
tags:
  - [Blog, jekyll, Github, Git]
use_math: true
toc: true
toc_sticky: true
 
date: 2021-02-25
last_modified_at: 2021-02-25
---

# 그래프의 정점을 어떻게 벡터로 표현할까

1. 정점 표현 학습

2. 인접성 기반 접근법

3. 거리/경로/중첩 기반 접근법

4. 임의보행 기반 접근법

5. 변환식 정점 표현 학습의 한계 

6. 실습 : Node2Vec을 사용한 군집 분석과 정점 분류

---

## 정점 표현 학습이란?

* 정점 표현 학습이란 그래프의 정점들을 벅터의 형태로 표현하는 것

* 정점 표현 학습은 정점 임베딩(Node Embedding)이라고도 한다.

* 정점이 표현되는 벡터공간을 임베딩 공간이라고 부른다.

* 정점 임베딩의 결과로, 벡터 형태의 데이터를 위한 도구들을 그래프에도 적용이 가능하다.

* 대부분의 분류기(로지스틱 회귀분석, 다층 퍼셉트론 등) 그리고 군집 분석 알고리즘(K-Means, DBSCAN등)은 벡터 형태로 표현된 Instance들을 입력받는다.

* 또한 정점 분류(Node Classification), 군집 분석(Community Detection)등에 활용이 가능하다.

* 정점을 벡터로 변환 할 때에는 그래프에서의 정점간 유사도를 임베딩 공간에서도 보존하는 것을 목표로 한다.

* 임베딩 공간에서의 유사도는 내적을 사용한다. $z_{u}^{T}z_{u}=\lVert z_{u} \rVert \cdot \lVert z_{v} \rVert \cdot cos(\theta)$ 내적값이 클 수록, 그리고 같은 방향을 향할 수록 큰 값을 가짐

---

## 인접성 기반 접근법

* 인접성 긴반 접근법은 두 정점이 인접할 때 유사하다고 간주한다.

* 인접행렬 $A$의 $u$행 $v$열 원소가 1이면 인접해있고 0이면 아닌 경우를 의미

![image-Adjacency](../../assets/img/boostcamp/Adjacency.png)

인접성만으로는 유사도를 판단하는 것은 한계가 있다. 거리에 대한 고려없이 간선으로 연결되어 있지 않으면 유사도가 0이 됨.

---

## 거리/경로/중첩 기반 접근법

![image-DistanceBased](../../assets/img/boostcamp/DistanceBased.png)

![image-PathBased](../../assets/img/boostcamp/PathBased.png)

![image-NestedBased](../../assets/img/boostcamp/NestedBased.png)

![image-NestedBased2](../../assets/img/boostcamp/NestedBased2.png)

* 만약 유명인의 트위터의 팔로워 간의 이웃일 확률은 매우 낮지만 팔로워 수가 적은 사람의 팔로워 간의 이웃일 확률은 높아진다. 그래서 가중치를 부여하여 합을 구한다.

---

## 임의보행 기반 접근법

* 임의보행 기반 접근법은 한 정점에서 시작하여 임의보행을 할 때 다른 정점에 도달할 확률을 유사도로 간주한다.

* ***임의보행*** 이란 현재 정점의 이웃 중 하나를 균일한 확률로 선택하여 이동하는 과정을 반복하는 것이다.

* 임의보행을 사용할 경우 시작 정점 주변의 지역적 정보와 그래프 전역 정보를 모두 고려한다는 장점이 있다.

![image-RandomWalk](../../assets/img/boostcamp/RandomWalk.png)

![image-RandomWalk2](../../assets/img/boostcamp/RandomWalk2.png)

![image-RandomWalk3](../../assets/img/boostcamp/RandomWalk3.png)

* 임의보행의 방법에 따라 DeepWalk와 Node2Vec으로 구분

* DeepWalk는 앞에서 설명한 현재 정점의 이웃 중 하나를 균일한 확률로 선택하여 이동하는 과정을 반복한다.

* Node2Vec은 2차 치우친 임의보행을 사용한다. 현재 정점과 직전에 머물렀던 정점을 모두 고려하여 다음 정점을 선택. 직전 정점의 거리를 기준으로 경우를 구분하여 차등적인 확률을 부여

* 임의보행 기법의 손실함수는 계산에 정점의 수의 제곱에 비례하는 시간이 소요된다. 따라서 많은 경우 근사식을 사용한다.

* 모든 정점에 대해서 정규화하는 대신 몇 개의 정점을 뽑아서 비교

![image-RandomWalkClose](../../assets/img/boostcamp/RandomWalkClose.png)

---

## 변환식 정점 표현 학습의 한계

* 지금까지 소개한 정점 임베딩 방법들은 변화식 방법이다. 변환식(Transductive) 방법은 학습의 결과로 정점의 임베딩 자제를 얻는다는 특성이 있다. 정점을 임베딩으로 변화시키는 함수인 인코더를 얻는 귀납식(Inductive)와 대조된다.

* 변환식 임베딩의 한계

    * 학습이 진행된 이후에 추가된 정점에 대해서는 임베딩을 얻을 수 없다.

    * 모든 정점에 대한 임베딩을 미리 계산하여 저장해야한다.

    * 정점이 속성 정보를 가진 경우에 이를 활용할 수 없다.

    * 이러한 단점을 해결하기 위한 귀납식 방법이 그래프 신경만(Graph Neural Network)

--- 

## 실습 : Node2Vec을 사용한 군집 분석 및 정점 분류

* [Node2Vec 실습](https://github.com/kyungminkim-dev/boostcamp-ai-tech/blob/main/Week5(Graph)/day22/%EC%8B%A4%EC%8A%B53_ipynb.ipynb){: target="_blank"} (수정 필요)



