---
title:  "P-stage Week1-day4"
excerpt: "AI Math"

categories:
  - Blog
tags:
  - [Blog, jekyll, Github, Git]
use_math: true
toc: true
toc_sticky: true
 
date: 2021-04-01
last_modified_at: 2021-04-01
---

* 시도해본 것 

    * resnet18 대신 resnet152를 사용해봤다. 더 깊은 레이어가 있는 만큼 더 높은 정확도를 기대했다. 레이어가 많으니 학습시간도 많이 걸렸다. 그러나 결과는 resnet18보다 좋지 못했다. epoch을 resnet18의 절반을 돌린것이 문제였는지 정확도가 56.63%에 그쳤다.

    * resnet18을 학습할 때, epoch수를 20으로 했다. epoch수를 2배 늘리면 정확도가 증가하는지 보기 위해 epoch을 40으로 설정하고 학습을 진행했다. 결과는 58.76%로 epoch을 20으로 설정했을 때 보다 오히려 낮게 나왔다.

    * vgg16을 써보았다. 처음에는 vgg16_bn을 사용하려 했으나 학습이 되지 않아 그냥 vgg16을 사용했다. vgg16모델의 마지막 fc레이어의 클래스 수를 18로 맞춰줄 때, resnet과 다르게 vgg16.classifier[6] 으로 접근해야 모델을 수정할 수 있다. 마지막 classifier레이어들이 Sequential에 묶여있기 때문이다. 

    * vgg16의 optimizer는 처음에 Adam을 사용했다. 그러나 학습이 진행되지 않아 SDG(lr=0.01)로 학습했다. 결과는 이때까지 가장 좋은 66.51%였다. vgg16역시 모델이 크다보니 학습하는데 시간이 오래걸렸고 epoch을 5로 설정했음에도 성과가 좋았다.

    * optimizer를 momentum으로 바꿔보았다. lr(=0.001)로 주고 학습했더니 정답률이 77.52%로 급격하게 상승했다. lr을 줄여서인지 momentum을 사용해서인지는 몰라도 정답률이 급격하게 상승해서 놀랐다. 

* 고민하고 있는 것

    * eval 데이터에 간단한 albumentation을 적용해 보고 싶다. 그럼 정확도가 더 올라가지 않을까 생각중이다.

    * train data와 valid data를 7:3비율로 나눠서 사용하고 있다. 솔직히 왜 나누는지 모르겠다. train data를 학습할 때는 backward를 통해 모델의 파라미터를 바꾼다. 근데 vaild data는 with torch.no_grad()를 사용해서 모델의 파라미터에 영향을 주지 않고 현재의 모델을 평가하기만 한다. 영향을 주지 않고 평가만 하는게 무슨 의미가 있는지 모르겠다. epoch을 한번 돌때마다 train_data와 vaild_data를 계속 섞어줘야 하는게 아닌지 궁금하다.

    * 모델의 학습 데이터를 만들때 albumentation을 적용했다. 코드를 보면 albumentaion적용 전의 데이터는 학습할 때 사용되지 않는 것 처럼 보인다. 원본 데이터도 같이 넣어서 학습시켜야 하는게 아닌가 싶다. 


    * 오늘 조교님께서 많은 학습 데이터 정제 방법을 알려주셨다. label smoothing, Knowledge Distillation, MixUp, Cosine Learning Rate Decay등이 있어다. 제일 쉬워보이는 label smoothing 부터 적용시켜 보려고 하는데 막막하다. 성능이 좋다고 들었는데 one-hot labeling 보다 얼마나 좋을지 궁금하다. 

    * backbone모델을 freeze한다는게 무슨 말인지 잘모르겠다. 앞으로 공부해나가야겠다. 다른 분들은 더 좋은 성능을 위해 데이터 전처리에 힘을 쓰는거 같아보였다. 데이터가 불균형 하다보니 균형을 맞추어 학습을 시키려는것 같았다. 나는 그냥 학습하기 급급한데 대단해보인다.

    
