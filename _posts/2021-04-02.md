---
title:  "P-stage Week1-day5"
excerpt: "AI Math"

categories:
  - Blog
tags:
  - [Blog, jekyll, Github, Git]
use_math: true
toc: true
toc_sticky: true
 
date: 2021-04-02
last_modified_at: 2021-04-02
---

* 시도해본 것

    * 이전의 코드들은 학습이 진행 될 때마다 loss값만 출력하도록 코딩이 되어 있었다. 리더보드의 평가가 micro f1 score값으로 진행되기 때문에 한번 학습이 될 때마다 micro f1 score값을 출력하도록 코딩을 해보았다. 먼저 f1 score에 대해 공부를 했다. multi class ML Model에서 f1 score를 구하는 방법은 각 class마다의 TP, FP, FN값을 구해 전부 더해준 뒤, f1 score를 구하는 식에 대입해서 구해준다.

    * sklearn에 f1 score를 구하는 함수가 있었지만 적용이 잘 안됐다. prediction과 target의 차원이 달라서 생기는 문제 같아 보인다. 따로 함수를 만들어서 사용하는 것이 좋아보인다.


    * vgg16의 feature를 고정하고 classifier 부분만 초기화 해서 학습을 진행 시켜보았다. 결과는 별로 좋지 못했다. 생각해보면 이전의 pretrain된 모델을 가져다 쓸 때, freeze를 시키지 않고 전부 파라미터가 업데이트 되게 학습시켰다. 그리고 freeze를 시키지 않은 모델이 더 정확도가 높았다. 그럼 pretrain된 모델을 왜 사용하고 왜 pretrain된 모델이 더 좋다고 말하는 이유는 무엇일까...

* 고민

    * 어제의 고민중 하나인 데이터를 albumentaion을 시키면 원본데이터를 사용하지 않고 albumentaion된 데이터만 모델의 학습에 이용된다고 한다. 그럼 평가를 할 때의 데이터는 전부 albumention을 적용하고 평가를 하면 정확도가 더 높게 나오는 것일까?...

    * pretrain된 모델을 학습할 때, feature 부분을 고정시키고 classifier 부분을 초기화 시키고 학습을 진행했다고 했는데 초기화 하지 않고 진행하면 어떻게 될지 궁금하다. 어차피 학습이 진행되다 보면 loss값이 줄어드는데 초기화가 중요한것일까..(중요하다고는 하는거 같다.) 초기화에 대한 공부가 더 필요하다.
