---
title:  "Day32 학습정리(Week7 CV) "
excerpt: "AI Math"

categories:
  - Blog
tags:
  - [Blog, jekyll, Github, Git]
use_math: true
toc: true
toc_sticky: true
 
date: 2021-03-09
last_modified_at: 2021-03-09
---

1. Problem with deeper layers

2. CNN architectures for image classification
    
    * GoogLeNet

    * ResNet

    * Beyond ResNet

3. Summary of image classification

4. Semantic segmentation 

5. Semantic segmentation architectures

    * FCN

    * Hypercolumns for object segmentation

    * U-Net

    * DeepLab

---

## Problem with deeper layers

* Deeper networks learn more powerful features, beacause of 

    * Lager receptive fileds

    * More capacity and non-linearity

* But Deeper networks are harder to optimize

    * Gradient vanishing / exploding

    * Computationally complex

    * ~~Overfitting problem~~ Degradation problem(정확도가 어느 순간 정체되고 레이어가 깊어질수록 성능이 더 나빠지는 현상)

---

## CNN architectures for image classification

* GoogLeNet(Inception v1)

    * GoogLeNet은 인셉션 모듈이라는 구조를 사용하여 파라미터 수는 감소시키면서 성능을 향상시켰다.

    * Use 1 X 1 convolutions as 'bottleneck' layers that reduce the number of channles

    ![image-Inception](../../assets/img/boostcamp/Inception.png)


    * Overall architecture

        * Stem network : vaniila convolution networks

        * Stacked inception modules 

        * Auxiliary classifiers

            * The vanishing gradient problem is dealt with this

            * Injecting additional gradients into lower layers

            * Used only during training, removed at testing tiem

        * Classifier output(a single FC layer)

* ResNet 

    * Revolution of depth 

    * Degradation problem을 해결

    ![image-Residual](../../assets/img/boostcamp/Residual.png)

    * Plain layer : As the layers get deeper, it is hard to learn good $H(x)$ directly

    * we learn residual $F(x)=H(x)-x$

    * Use layers to fit a residual mapping instead of directly fitting a desired underlying mapping 

    * The vanishing gradient problem is solved by shortcut connetion 

* Beyond ResNet 

    * DenseNet

    * SENet

    * EfficientNet

---

## Summary of image classification

![image-Summary](../../assets/img/boostcamp/Summary.png)

* GoogLeNet is the most efficient CNN model. But, it is complicatedd to use

* Instead, VGGNet and ResNet are typically used as a backbone model for many tasks.(Cause constructed with simple 3 X 3 conv)

---

## Semantic segmentaion

* Classify each pixel of an image into a category

* Don't care about instance. Only care about semantic category

---

## Semantic segmentation architectures

* Fully Convolutional Networks(FCN)

    * Fully connected layer(FC) : Output a fixed dimensional vector and discard spatial coordinates

    * Fully convolutional layer : Output a classification map which has spatial coordinates

    ![image-FC](../../assets/img/boostcamp/FC.png)

* Upsampling 

    * FCN을 통하여 나온 Predicted score map의 해상도가 너무 낮다. 이를 해결하기 위해 Upsampling을 통해 score map의 크기를 키운다.

